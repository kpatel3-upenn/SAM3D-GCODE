{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geometry\n",
    "import scale_transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case: 128*128*128 matrix with 64^3 in the center\n",
    "test_1 = np.zeros((128, 128, 128))\n",
    "test_1[32:96, 32:96, 32:96] = 255\n",
    "test_1 = np.zeros((128, 128, 128))\n",
    "test_2=np.ones((128,128,128))\n",
    "for i in range(128):\n",
    "    for j in range(128):\n",
    "        for k in range(128):\n",
    "            if ((i-64)**2+(j-64)**2+(k-64)**2)**0.5>50:\n",
    "                test_2[i,j,k]=0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     transform_list\u001b[38;5;241m.\u001b[39mappend(geometry\u001b[38;5;241m.\u001b[39mTransform(a, translation\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transform_list:\n\u001b[0;32m----> 8\u001b[0m     transformed_img, _ \u001b[38;5;241m=\u001b[39m \u001b[43mscale_transform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_to_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     slice_transformed_img \u001b[38;5;241m=\u001b[39m test_1[:,:,test_1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     10\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./slices_for_prompting/slice_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, slice_transformed_img)\n",
      "File \u001b[0;32m~/Desktop/3D_segment/SAM3D/scale_transform.py:42\u001b[0m, in \u001b[0;36mglobal_to_local\u001b[0;34m(image, transform)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglobal_to_local\u001b[39m (image, transform):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_to_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/3D_segment/SAM3D/geometry.py:191\u001b[0m, in \u001b[0;36mTransform.apply_to_array\u001b[0;34m(self, array, scale, padwith, inverse, order, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m     translated \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(translated, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     translated \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadwith\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m offset \u001b[38;5;241m=\u001b[39m center \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation\u001b[38;5;241m.\u001b[39mapply(center)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/ndimage/_interpolation.py:738\u001b[0m, in \u001b[0;36mshift\u001b[0;34m(input, shift, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shift\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[1;32m    737\u001b[0m     shift \u001b[38;5;241m=\u001b[39m shift\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 738\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "angle_list = [(0,0,0), (np.pi/2,0,0), (0,np.pi/2,0), (0,0,np.pi/2), (np.pi/4,0,0), (0,np.pi/4,0), (0,0,np.pi/4), (np.pi/8,0,0), (0,np.pi/8,0), (0,0,np.pi/8)]\n",
    "transform_list = []\n",
    "\n",
    "for a in angle_list:\n",
    "    transform_list.append(geometry.Transform(a, translation=(0, 0, 0)))\n",
    "\n",
    "for t in transform_list:\n",
    "    transformed_img, _ = scale_transform.global_to_local(test_1, t)\n",
    "    slice_transformed_img = test_1[:,:,test_1.shape[2]//2]\n",
    "    cv2.imwrite(f'./slices_for_prompting/slice_{a}.png', slice_transformed_img)\n",
    "\n",
    "# add\n",
    "# sliced_transformed_test_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_dir):\n",
    "    img = plt.imread(img_dir)\n",
    "    return img\n",
    "\n",
    "# load image files and save prompt points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test matrix\n",
    "\n",
    "# get the list of transforms\n",
    "\n",
    "# slice the matrix using global_to_local function. Do it to every transform.\n",
    "\n",
    "# Add prompting:\n",
    "    # save slices to image files (naming convention: 001.png)\n",
    "    # open image files and save prompt points to jason \n",
    "\n",
    "# convert prompt points to zero_centric coordinates using index_to_coord\n",
    "\n",
    "# for each transform:\n",
    "    # calculate the rotated array\n",
    "    # for n slices:\n",
    "        # get the slice of the rotated array,\n",
    "        # calculate the prompts intersecting with that slice\n",
    "        # feed into SAM inference function\n",
    "        # Get mask points for that slice\n",
    "        # Convert to global coord, append to list of global mask points\n",
    "        \n",
    "# take global mask points, convert to volumetric mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the notebook we will use\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
